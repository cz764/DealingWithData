{
 "metadata": {
  "colabVersion": "0.1",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Redirection\n",
      "-----------\n",
      "\n",
      "### The `>` operator\n",
      "\n",
      "A very important command-line operator is the \u201credirection\u201d operator \u201c`>`\u201d.  With \u201c`>`\u201d you can send the result of your command-line processing to a file.  So if you\u2019re using curl to get your current location, using the ip-api.com service (see the previous section) and want to store the output into a file, you can create a new file with just these lines using redirection:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl 'http://ip-api.com/json' > location.json\n",
      "\n",
      "!curl 'http://ip-api.com/json' -o location2.json\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100   311    0   311    0     0   1964      0 --:--:-- --:--:-- --:--:--  7404\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see the content of the file, we can use the command `cat` (described below)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat location.json"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": {
       "content": {
        "execution_count": 1,
        "payload": [],
        "status": "ok",
        "user_expressions": {},
        "user_variables": {}
       },
       "timestamp": 1409762051553,
       "user": {
        "color": "#1FA15D",
        "displayName": "Panos Ipeirotis",
        "isAnonymous": false,
        "isMe": true,
        "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAA0Ro/MROYPWvY51A/s50-c-k-no/photo.jpg",
        "sessionId": "67a2c480bd9c6290",
        "userId": "103666871486129948108"
       },
       "user_tz": 240
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"status\":\"success\",\"country\":\"United States\",\"countryCode\":\"US\",\"region\":\"NY\",\"regionName\":\"New York\",\"city\":\"New York\",\"zip\":\"10009\",\"lat\":\"40.7252\",\"lon\":\"-73.9802\",\"timezone\":\"America\\/New_York\",\"isp\":\"Verizon FiOS\",\"org\":\"Verizon FiOS\",\"as\":\"AS701 MCI Communications Services, Inc. d\\/b\\/a Verizon Business\",\"query\":\"108.41.148.194\"}"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The `>>` operator\n",
      "\n",
      "If we want to append to a file (instead of creating a new file from scratch), then we can use the `>>` operator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl 'http://ip-api.com/json' > alldata.txt\n",
      "!curl \"http://api.openweathermap.org/data/2.5/weather?lat=40.72&lon=-73.98&units=imperial&mode=json\" >> alldata.txt \n",
      "!cat alldata.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100   338    0   338    0     0   1217      0 --:--:-- --:--:-- --:--:--  2816\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100   436    0   436    0     0   4093      0 --:--:-- --:--:-- --:--:-- 18166\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"status\":\"success\",\"country\":\"United States\",\"countryCode\":\"US\",\"region\":\"NY\",\"regionName\":\"New York\",\"city\":\"New York\",\"zip\":\"10009\",\"lat\":\"40.7252\",\"lon\":\"-73.9802\",\"timezone\":\"America\\/New_York\",\"isp\":\"Verizon FiOS\",\"org\":\"Verizon FiOS\",\"as\":\"AS701 MCI Communications Services, Inc. d\\/b\\/a Verizon Business\",\"query\":\"108.41.148.194\"}{\"coord\":{\"lon\":-73.98,\"lat\":40.72},\"sys\":{\"type\":1,\"id\":2120,\"message\":0.1,\"country\":\"US\",\"sunrise\":1410085764,\"sunset\":1410131881},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04d\"}],\"base\":\"cmc stations\",\"main\":{\"temp\":75.94,\"pressure\":1019,\"humidity\":53,\"temp_min\":73,\"temp_max\":78.8},\"wind\":{\"speed\":6.7,\"deg\":360},\"clouds\":{\"all\":75},\"dt\":1410112198,\"id\":5125125,\"name\":\"Long Island City\",\"cod\":200}\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pipes\n",
      "-----\n",
      "\n",
      "Pipes provide a way of connecting the output of one unix program or utility to the input of another, through standard input and output. \n",
      "\n",
      "Unix pipes give you the power to compose various utilities into a data flow and use your creativity to solve problems. Utilities are connected together (\"piped\" together) via the pipe operator, |. \n",
      "\n",
      "We will give more examples that use piper later, after covering a few useful utilities first."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filters\n",
      "-------\n",
      "\n",
      "###`cat`:\n",
      "\n",
      "Prints the contents of the specified files to standard output. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s -L 'https://googledrive.com/host/0BzX1e06EhsXSc20xU2JNcFoxbGc/sample.txt' -o sample.txt #retrieve the file\n",
      "!cat sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we also want to number the lines, we use the `-n` option:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat -n sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     1\t123\t1346699925\t11122\tfoo bar\r\n",
        "     2\t222\t1346699955\t11145\tbiz baz\r\n",
        "     3\t140\t1346710000\t11122\thee haw\r\n",
        "     4\t234\t1346700000\t11135\tbip bop\r\n",
        "     5\t146\t1346699999\t11123\tfoo bar\r\n",
        "     6\t99\t1346750000\t11135\tbip bop\r\n",
        "     7\t99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "* Let's get now the \"Restaurant Inspection Results_\" results from the [NYC Open Data](https://nycopendata.socrata.com/) website.\n",
      "\n",
      "* Click on the top \"1100+ Data Sets available\" and then search for the term \"_Restaurant Inspection Results_\"\n",
      "\n",
      "* Go to the data set and get the link for downloading the ZIP file.\n",
      "\n",
      "* To download it into your machine, type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s -L \"<put the URL here>\" -o restaurant.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note 1: The -L flag tells curl to follow \"redirects\" and -s tells curl not to print any output or statistics but rather store the file in the file specified by the -o flag.)\n",
      "\n",
      "Note 2: This dataset is a zipped version of the original \"DOHMH New York City Restaurant Inspection Results\", which is pretty big (>100Mb). \n",
      "\n",
      "Note 3: We need to unzip the file to get the contents. The `unzip` command can be installed using `sudo apt-get install unzip`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `head/tail`:\n",
      "\n",
      "Output the first (last) lines of a file. Typically used like:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 5 sample.txt "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!tail -n 5 sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The -n option specifies the number of lines to be output, the default value is 10. tail, when used with the -f option, will output the end of a file as it is written to. This is useful is a program is writing output or logging progress to a file, and you want to read it as it is happening."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`less`:\n",
      "\n",
      "The command `cat` lets you see the contents of the file, but it is not convenient when the file is big. For that, it is better to use the command `less` which allows you to scroll and navigate through the contents of a file. When invoked like: `less [some big file]`. `less` enters an interactive mode. In this mode, several keys help you navigate the input file. Some key commands are:\n",
      "\n",
      "+ `(space)`: space navigates forward one screen.\n",
      "+ `(enter)`: enter navigates forward one line.\n",
      "+ `b`: navigates backwards one screen\n",
      "+ `y`: navigates backwards one line.\n",
      "+ `/[pattern]`: search forwards for the next occurrence of `[pattern]`\n",
      "+ `?[pattern]`: search backwards for the previous occurrence of `[pattern]`\n",
      "\n",
      "Where `[pattern]` can be a basic string or a regular expression. (We will cover regular expressions in the next session)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`sort`\n",
      "\n",
      "An extremely efficient implementation of [external merge sort](http://dzmitryhuba.blogspot.com/2010/08/external-merge-sort.html). In a nutshell, this means the sort utility can order a dataset far larger than can fit in a system\u2019s main memory. While sorting extremely large files does drastically increase the runtime, smaller files are sorted quickly. Useful both as a component of larger shell scripts, and independently, as a tool to, say, quickly find the most active users, or to see the  most frequently loaded pages on a domain. \n",
      "\n",
      "Typically called like: `sort [options] [file]`. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Some useful options:\n",
      "\n",
      "+ `-r`: reverse order. Sort the input in descending order:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -r sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "123\t1346699925\t11122\tfoo bar\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-n`: numeric order. Sort the input in numerical order as opposed to the default lexicographical order:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "123\t1346699925\t11122\tfoo bar\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "234\t1346700000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-k n`: sort the input according to the values in the n-th column. Useful for columnar  data. See also the -t option to specify the text used to specify columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -k 2 sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "Sort the NYC Restaurant dataset by restaurant name. You will see that this is a comma separated file therefore the character that separates columns is the `,` (comma) character. The restaurant name is the second column in the dataset."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`uniq`\n",
      "\n",
      "Remove sequential duplicates: prints only those unique sequential lines from a file. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!uniq sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Used with the `-c` option, uniq will report the number of duplicates of each line in the sequence. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!uniq -c sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`wc`: \n",
      "Compute word, line, and byte counts for specified files or output of other scripts. Particularly useful when used in concert with other utilities such as grep, sort, and uniq. Example usage:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  7  35 201 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Indicating the number of lines, words, and bytes in the file respectively. There are some useful flags for wc that will help you answer specific questions quickly:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-l`: get the number of lines from the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -l sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-w`: get the number of words in the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -w sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "35 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-m`: the number of characters in the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -m sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "201 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-c`: the number of bytes in the input. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -c sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "201 sample.txt\r\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the number of bytes and characters are the same; all characters used are just one byte."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`cut`:\n",
      "\n",
      "Used to select or \u201ccut\u201d certain fields (usually columns) from input. Cut is typically used with the `-f` option to specify a comma-separated list of columns to be emitted. Example:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An important option with the cut utility is `-d`, which is used to specify the string used to separate the fields in the input. While the default value of tab is appropriate for our sample file, if spaces were used instead of tabs, we could change the above command to:\n",
      "\n",
      "`cut -d\" \" -f2,4 sample.txt`\n",
      "\n",
      "### Exercise\n",
      "\n",
      "* Get the restaurant names from the NYC Restaurant dataset\n",
      "* Remove any duplicate names\n",
      "* Sort the deduplicateds results\n",
      "* Report how many unique restaurants are in the dataset\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cut -f2,4 sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cut -f2 -d\",\"  /tmp/WebExtract.txt > /tmp/RestaurantNames.txt\n",
      "!sort /tmp/RestaurantNames.txt > /tmp/SortedRestaurantNames.txt\n",
      "\n",
      "!uniq -c /tmp/SortedRestaurantNames.txt > /tmp/UniqueNames.txt\n",
      "!head -10 /tmp/UniqueNames.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     35 \"\"U\" LIKE CHINESE RESTAURANT\"\r\n",
        "     30 \"#1 GARDEN CHINESE\"\r\n",
        "     22 \"#1 MR. NICK'S PIZZA & PASTA\"\r\n",
        "     47 \"#1 SABOR LATINO RESTAURANT\"\r\n",
        "     16 \"$1.25 PIZZA\"\r\n",
        "     44 \"'SNICE\"\r\n",
        "     27 \"'WICHCRAFT\"\r\n",
        "     23 \"(LEWIS DRUG STORE) LOCANDA VINI E OLII\"\r\n",
        "     28 \"(PUBLIC FARE) 81st street and central park west (Delacorte Theatre)\"\r\n",
        "     16 \"/ L'ECOLE\"\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r /tmp/UniqueNames.txt > count.txt\n",
      "!less count.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b7\u001b[?47h\u001b[?1h\u001b=\r",
        "   5039 \"SUBWAY\"\r\n",
        "   4013 \"MCDONALD'S\"\r\n",
        "   2828 \"DUNKIN' DONUTS\"\r\n",
        "   2020 \"STARBUCKS COFFEE\"\r\n",
        "   1785 \"DUNKIN DONUTS\"\r\n",
        "   1628 \"CROWN FRIED CHICKEN\"\r\n",
        "   1456 \"BURGER KING\"\r\n",
        "   1425 \"KENNEDY FRIED CHICKEN\"\r\n",
        "   1289 \"DOMINO'S PIZZA\"\r\n",
        "   1164 \"DUNKIN' DONUTS\r\n",
        "    840 \"GOLDEN KRUST CARIBBEAN BAKERY & GRILL\"\r\n",
        "    830 \"POPEYES CHICKEN & BISCUITS\"\r\n",
        "    682 \"CHIPOTLE MEXICAN GRILL\"\r\n",
        "    653 \"PAPA JOHN'S\"\r\n",
        "    600 \"WENDY'S\"\r\n",
        "    596 \"IHOP\"\r\n",
        "    592 \"CARVEL ICE CREAM\"\r\n",
        "    485 \"AU BON PAIN\"\r\n",
        "    436 \"LITTLE CAESARS\"\r\n",
        "    413 \"PRET A MANGER\"\r\n",
        "    411 \"BOSTON MARKET\"\r\n",
        "    392 \"PRONTO PIZZA\"\r\n",
        "    361 \"CHECKERS\"\r\n",
        "\u001b[7mcount.txt\u001b[m\u001b[K"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of having four lines of data processing, we can use pipes to one single line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cut -f2 -d\",\" /tmp/WebExtract.txt | sort | uniq -c | sort -r -n | head -10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###`grep`:\n",
      "A utility for pattern matching. grep is by far the most useful unix utility. While grep is conceptually very simple, an effective developer or data scientist will no doubt find themselves using grep dozens of times a day. grep is typically called like this: `grep [options] [pattern] [files]`. With no options specified, this simply looks for the specified pattern in the given files, printing to the console only those lines that match the given pattern. Example:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This in itself can be very useful, scraping large volumes of data to find what you\u2019re looking for. \n",
      "\n",
      "The power of grep really shows when different command options are specified. Below are just a sample of the more useful grep options:\n",
      "\n",
      "+ `-v`: Inverted matching. In this setting, grep will return all the input lines that do not match the specified pattern. Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'biz baz' sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "222\t1346699955\t11145\tbiz baz\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'foo bar' sample.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'foo bar' sample.txt | wc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      2      10      58\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'foo bar' sample.txt | wc -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ `-R`: Recursive matching. Here grep descends sub folders, applying the pattern on all files encountered. Very useful if you\u2019re looking to see if any logs have lines that you\u2019re interested in, or to find the source code file containing the function you\u2019re interested in. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd /vagrant/\n",
      "!grep -R 'Wikipedia' ."
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "./.ipynb_checkpoints/Session #1 (Basic Unix Shell Commands and CURL)-checkpoint.ipynb:      \"And now just a demo of a web API that I created myself a few years back. It analyzes Wikipedia to figure out different ways that people use to refer to the same entity\\n\",\r\n",
        "./.ipynb_checkpoints/Session 1 (Basic Unix Shell Commands and CURL)-checkpoint.ipynb:      \"And now just a demo of a web API that I created myself a few years back. It analyzes Wikipedia to figure out different ways that people use to refer to the same entity\\n\",\r\n",
        "./Session 1 (Basic Unix Shell Commands and CURL).ipynb:      \"And now just a demo of a web API that I created myself a few years back. It analyzes Wikipedia to figure out different ways that people use to refer to the same entity\\n\",\r\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More options:\n",
      "\n",
      "* -c\tPrint only a count of matched lines.\n",
      "* -i \tIgnore lowercase and uppercase distinctions\n",
      "* -n\tPrint matching line with its line number\n",
      "* -v  \tNegate matches; print lines that do not match the regex\n",
      "* -r\tRecursively Search subdirectories listed\n",
      "* -l \tList only filenames\n",
      "* -o\tprints only the matching part of the line\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will get back to grep next session, once we learn regular expressions. You will see that grep can be extremely useful for searching through data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `jq`\n",
      "\n",
      "The [jq](http://stedolan.github.io/jq/) is not one of the \"standard\" UNIX tools but will be useful for us, to be able to parse the JSON responses of the Web API calls.\n",
      "\n",
      "Since it is not installed by default, we need to first install it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sudo apt-get install jq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Reading package lists... 0%\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Reading package lists... 100%\r",
        "\r",
        "Reading package lists... Done\r",
        "\r\n",
        "\r",
        "Building dependency tree... 0%\r",
        "\r",
        "Building dependency tree... 0%\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Building dependency tree... 50%\r",
        "\r",
        "Building dependency tree... 50%\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Building dependency tree       \r",
        "\r\n",
        "\r",
        "Reading state information... 0%\r",
        "\r",
        "Reading state information... 0%\r",
        "\r",
        "Reading state information... Done\r",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "jq is already the newest version.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 upgraded, 0 newly installed, 0 to remove and 157 not upgraded.\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `jq` command has the format\n",
      "\n",
      "`jq [filters] filename`\n",
      "\n",
      "\n",
      "\n",
      "The absolute simplest (and least interesting) filter is `.` \n",
      "\n",
      "This is a filter that takes its input and produces it unchanged as output.\n",
      "\n",
      "Since jq by default \"pretty-prints\" all output, this trivial program can be a useful way of formatting JSON output from, say, curl.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!jq . location.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[37m{\r\n",
        "  \u001b[0m\u001b[34;1m\"query\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"108.41.148.194\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"as\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"AS701 MCI Communications Services, Inc. d/b/a Verizon Business\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"org\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Verizon FiOS\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"isp\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Verizon FiOS\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"timezone\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"America/New_York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"lon\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"-73.9802\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"status\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"success\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"United States\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"countryCode\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"US\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"region\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"NY\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"regionName\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"New York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"city\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"New York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"zip\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"10009\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"lat\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"40.7252\"\u001b[0m\u001b[37m\r\n",
        "\u001b[37m}\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having learned pipes, we can now avoid storing the output of curl into a file, and instead pass it directly through `jq`: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://ip-api.com/json' | jq . "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[37m{\r\n",
        "  \u001b[0m\u001b[34;1m\"query\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"108.41.148.194\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"as\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"AS701 MCI Communications Services, Inc. d/b/a Verizon Business\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"org\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Verizon FiOS\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"isp\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"Verizon FiOS\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"timezone\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"America/New_York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"lon\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"-73.9802\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"status\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"success\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"country\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"United States\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"countryCode\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"US\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"region\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"NY\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"regionName\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"New York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"city\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"New York\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"zip\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"10009\"\u001b[0m\u001b[37m,\r\n",
        "  \u001b[0m\u001b[34;1m\"lat\"\u001b[0m\u001b[37m: \u001b[0m\u001b[32m\"40.7252\"\u001b[0m\u001b[37m\r\n",
        "\u001b[37m}\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(The -s option for curl stands for \"silent\" and prevents the status messages from appearing in the output).\n",
      "\n",
      "The simplest useful filter is `.foo`. When given a JSON object as input, it produces the value at the attribute `foo`, or null if there\u2019s none present.\n",
      "\n",
      "Now, let's try to use such a filter for selecting the \"city\" attribute listed in the JSON output: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://ip-api.com/json' | jq '.city'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[32m\"New York\"\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can also combine multiple attributes, using the addition operator `+`: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://ip-api.com/json' | jq '.city + \", \" + .region'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[32m\"New York, NY\"\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's try something more complicated: We will use the jq command to read the location from the output of the ip-api.com API, and then create the URL for calling the OpenWeathermap API (see the previous session for details):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://ip-api.com/json' | jq '\"http://api.openweathermap.org/data/2.5/weather?q=\" + .city + \", \" + .region + \"&mode=json&units=imperial\"'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[32m\"http://api.openweathermap.org/data/2.5/weather?q=New York, NY&mode=json&units=imperial\"\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, let's also use the `xargs` command (covered below), in order to call this URL directly, and get the weather in our current location:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -s 'http://ip-api.com/json' | \\\n",
      "jq '\"http://api.openweathermap.org/data/2.5/weather?q=\" + .city + \", \" + .region + \"&mode=json&units=imperial\"' | \\\n",
      "xargs -L 1 curl -s | jq '.main.temp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "curl: no URL specified!\r\n",
        "curl: try 'curl --help' or 'curl --manual' for more information\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Look at the power of pipes and filters: In three lines and in less than 200 characters, we created a service that reads out current location, using the API at ip-api.com, parses the output, creates a new API call for OpenWeatherMap, and then gets the data from that service, to give us back the temperature in our current location!\n",
      "\n",
      "The full manual of `jq` is available at http://stedolan.github.io/jq/manual/ and you can use the live demo at https://jqplay.org/\n",
      "\n",
      "There are numerous options in the manual. For now, you can restrict yourself to the basic operations that we covered."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Exercises\n",
      "\n",
      "* Instead of reading the city and region, read instead the log/lat coordinates, and modify the API call to OpenWeatherMap to use long/lat instead. (See http://openweathermap.org/current for the details API calls.)\n",
      "\n",
      "* Print the description of the weather, instead of the temperature."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More examples of using pipes\n",
      "----------------------------\n",
      "\n",
      "We discussed earlier in the session the usage of the `|` operator to connect (aka \"pipe\") the output of one utility and direct it as input in another. Now that we have learned a few tools, lets use these in some examples. For instance, if you want to know how many records in the sample data file do not contain \"foo bar\", you can compose a data flow like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | grep -v 'foo bar' | wc -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using `wc` at the end of a pipe to count the number of matching output records is a common pattern. Recalling that `uniq` removes any sequential duplicates, we can count the number of unique users making purchases in our file by composing a data flow like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | cut -f3 | sort | uniq  | wc -l"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       4\r\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or, if you want count how many transactions each user has appeared in:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | cut -f3 | sort | uniq -c"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   2 11122\r\n",
        "   1 11123\r\n",
        "   3 11135\r\n",
        "   1 11145\r\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To now order the users by number of transactions made, you can try something like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample.txt | cut -f3 | sort | uniq -c | sort -nr"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   3 11135\r\n",
        "   2 11122\r\n",
        "   1 11145\r\n",
        "   1 11123\r\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice here, that the `-r` and `-n` flags for the sort command are combined. This is common shorthand and is acceptable for any unix utility."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More Useful Command Line Utilities:\n",
      "-----------------------------------\n",
      "\n",
      "+ [`xargs`](http://linux.die.net/man/1/xargs): used for building and executing terminal commands. Often used to read input from a pipe, and perform the same command on each line read from the pipe. For instance, if we want to look up all of the .txt files in a directory and concatenate them, we can use xargs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls . | grep '.txt' | xargs cat"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123\t1346699925\t11122\tfoo bar\r\n",
        "222\t1346699955\t11145\tbiz baz\r\n",
        "140\t1346710000\t11122\thee haw\r\n",
        "234\t1346700000\t11135\tbip bop\r\n",
        "146\t1346699999\t11123\tfoo bar\r\n",
        "99\t1346750000\t11135\tbip bop\r\n",
        "99\t1346750000\t11135\tbip bop\r\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ [`find`](http://linux.die.net/man/1/find): search directories for matching files. Useful when you know the name of a file (or part of the name), but do not know the file\u2019s location in a directory. Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!find . -name 'sample.txt'"
     ],
     "language": "python",
     "metadata": {
      "cellView": null,
      "executionInfo": null
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "./sample.txt\r\n"
       ]
      }
     ]
    }
   ],
   "metadata": {}
  }
 ]
}